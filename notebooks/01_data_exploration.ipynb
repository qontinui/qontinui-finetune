{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Exploration and Analysis\n",
        "\n",
        "This notebook explores the dataset structure, visualizes samples, and performs statistical analysis on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Data processing and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.patches import Rectangle\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Deep learning\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "%matplotlib inline\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Loading and Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define dataset paths\n",
        "DATASET_ROOT = Path('/path/to/dataset')  # Update with actual dataset path\n",
        "IMAGES_DIR = DATASET_ROOT / 'images'\n",
        "LABELS_DIR = DATASET_ROOT / 'labels'\n",
        "\n",
        "# List dataset splits\n",
        "print(\"Dataset Structure:\")\n",
        "for split in ['train', 'val', 'test']:\n",
        "    split_images = list((IMAGES_DIR / split).glob('*.jpg')) if (IMAGES_DIR / split).exists() else []\n",
        "    split_labels = list((LABELS_DIR / split).glob('*.txt')) if (LABELS_DIR / split).exists() else []\n",
        "    print(f\"  {split}: {len(split_images)} images, {len(split_labels)} labels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Class Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_class_distribution(labels_dir, split='train'):\n",
        "    \"\"\"Analyze class distribution in the dataset.\"\"\"\n",
        "    class_counts = Counter()\n",
        "    total_annotations = 0\n",
        "    \n",
        "    label_files = list((labels_dir / split).glob('*.txt'))\n",
        "    \n",
        "    for label_file in label_files:\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f:\n",
        "                class_id = int(line.split()[0])\n",
        "                class_counts[class_id] += 1\n",
        "                total_annotations += 1\n",
        "    \n",
        "    return class_counts, total_annotations\n",
        "\n",
        "# Analyze training data\n",
        "class_counts, total_annots = analyze_class_distribution(LABELS_DIR)\n",
        "\n",
        "print(f\"Total annotations: {total_annots}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "for class_id in sorted(class_counts.keys()):\n",
        "    count = class_counts[class_id]\n",
        "    percentage = (count / total_annots) * 100\n",
        "    print(f\"  Class {class_id}: {count:5d} ({percentage:6.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create class distribution visualization\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart\n",
        "classes = sorted(class_counts.keys())\n",
        "counts = [class_counts[c] for c in classes]\n",
        "axes[0].bar(classes, counts, color='steelblue')\n",
        "axes[0].set_xlabel('Class ID', fontsize=12)\n",
        "axes[0].set_ylabel('Number of Annotations', fontsize=12)\n",
        "axes[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Pie chart\n",
        "colors = plt.cm.Set3(np.linspace(0, 1, len(classes)))\n",
        "axes[1].pie(counts, labels=[f'Class {c}' for c in classes], autopct='%1.1f%%',\n",
        "            colors=colors, startangle=90)\n",
        "axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bounding Box Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_bbox_statistics(labels_dir, images_dir, split='train'):\n",
        "    \"\"\"Analyze bounding box dimensions and positions.\"\"\"\n",
        "    bbox_widths = []\n",
        "    bbox_heights = []\n",
        "    bbox_areas = []\n",
        "    aspect_ratios = []\n",
        "    \n",
        "    label_files = list((labels_dir / split).glob('*.txt'))\n",
        "    \n",
        "    for label_file in label_files:\n",
        "        # Get image dimensions\n",
        "        img_name = label_file.stem + '.jpg'\n",
        "        img_path = images_dir / split / img_name\n",
        "        \n",
        "        if not img_path.exists():\n",
        "            continue\n",
        "            \n",
        "        img = Image.open(img_path)\n",
        "        img_w, img_h = img.size\n",
        "        \n",
        "        # Parse bounding boxes (YOLO format: class_id, x_center, y_center, width, height)\n",
        "        with open(label_file, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = list(map(float, line.strip().split()))\n",
        "                if len(parts) >= 5:\n",
        "                    bbox_w = parts[3] * img_w\n",
        "                    bbox_h = parts[4] * img_h\n",
        "                    bbox_widths.append(bbox_w)\n",
        "                    bbox_heights.append(bbox_h)\n",
        "                    bbox_areas.append(bbox_w * bbox_h)\n",
        "                    if bbox_h > 0:\n",
        "                        aspect_ratios.append(bbox_w / bbox_h)\n",
        "    \n",
        "    return {\n",
        "        'widths': bbox_widths,\n",
        "        'heights': bbox_heights,\n",
        "        'areas': bbox_areas,\n",
        "        'aspect_ratios': aspect_ratios\n",
        "    }\n",
        "\n",
        "bbox_stats = analyze_bbox_statistics(LABELS_DIR, IMAGES_DIR)\n",
        "\n",
        "print(\"Bounding Box Statistics:\")\n",
        "print(f\"\\n  Width:\")\n",
        "print(f\"    Mean: {np.mean(bbox_stats['widths']):.2f} px\")\n",
        "print(f\"    Std: {np.std(bbox_stats['widths']):.2f} px\")\n",
        "print(f\"    Min: {np.min(bbox_stats['widths']):.2f} px\")\n",
        "print(f\"    Max: {np.max(bbox_stats['widths']):.2f} px\")\n",
        "\n",
        "print(f\"\\n  Height:\")\n",
        "print(f\"    Mean: {np.mean(bbox_stats['heights']):.2f} px\")\n",
        "print(f\"    Std: {np.std(bbox_stats['heights']):.2f} px\")\n",
        "print(f\"    Min: {np.min(bbox_stats['heights']):.2f} px\")\n",
        "print(f\"    Max: {np.max(bbox_stats['heights']):.2f} px\")\n",
        "\n",
        "print(f\"\\n  Area:\")\n",
        "print(f\"    Mean: {np.mean(bbox_stats['areas']):.2f} px²\")\n",
        "print(f\"    Median: {np.median(bbox_stats['areas']):.2f} px²\")\n",
        "\n",
        "print(f\"\\n  Aspect Ratio (W/H):\")\n",
        "print(f\"    Mean: {np.mean(bbox_stats['aspect_ratios']):.2f}\")\n",
        "print(f\"    Median: {np.median(bbox_stats['aspect_ratios']):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Bounding Box Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create bounding box statistics visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Width distribution\n",
        "axes[0, 0].hist(bbox_stats['widths'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_xlabel('Width (pixels)', fontsize=11)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=11)\n",
        "axes[0, 0].set_title('Bounding Box Width Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Height distribution\n",
        "axes[0, 1].hist(bbox_stats['heights'], bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_xlabel('Height (pixels)', fontsize=11)\n",
        "axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
        "axes[0, 1].set_title('Bounding Box Height Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Area distribution\n",
        "axes[1, 0].hist(bbox_stats['areas'], bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
        "axes[1, 0].set_xlabel('Area (pixels²)', fontsize=11)\n",
        "axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
        "axes[1, 0].set_title('Bounding Box Area Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Aspect ratio distribution\n",
        "axes[1, 1].hist(bbox_stats['aspect_ratios'], bins=50, color='plum', edgecolor='black', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Aspect Ratio (W/H)', fontsize=11)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
        "axes[1, 1].set_title('Bounding Box Aspect Ratio Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Image Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_image_quality(images_dir, split='train'):\n",
        "    \"\"\"Analyze image dimensions and properties.\"\"\"\n",
        "    widths = []\n",
        "    heights = []\n",
        "    file_sizes = []\n",
        "    image_info = []\n",
        "    \n",
        "    img_files = list((images_dir / split).glob('*.jpg'))\n",
        "    \n",
        "    for img_path in img_files:\n",
        "        try:\n",
        "            img = Image.open(img_path)\n",
        "            w, h = img.size\n",
        "            file_size = os.path.getsize(img_path) / (1024 * 1024)  # Convert to MB\n",
        "            \n",
        "            widths.append(w)\n",
        "            heights.append(h)\n",
        "            file_sizes.append(file_size)\n",
        "            \n",
        "            image_info.append({\n",
        "                'filename': img_path.name,\n",
        "                'width': w,\n",
        "                'height': h,\n",
        "                'size_mb': file_size\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {e}\")\n",
        "    \n",
        "    return {\n",
        "        'widths': widths,\n",
        "        'heights': heights,\n",
        "        'file_sizes': file_sizes,\n",
        "        'image_info': image_info\n",
        "    }\n",
        "\n",
        "quality_stats = analyze_image_quality(IMAGES_DIR)\n",
        "\n",
        "print(f\"Image Quality Statistics ({len(quality_stats['widths'])} images):\")\n",
        "print(f\"\\n  Resolution:\")\n",
        "print(f\"    Mean: {np.mean(quality_stats['widths']):.0f}x{np.mean(quality_stats['heights']):.0f}\")\n",
        "print(f\"    Min: {np.min(quality_stats['widths']):.0f}x{np.min(quality_stats['heights']):.0f}\")\n",
        "print(f\"    Max: {np.max(quality_stats['widths']):.0f}x{np.max(quality_stats['heights']):.0f}\")\n",
        "\n",
        "print(f\"\\n  File Size:\")\n",
        "print(f\"    Mean: {np.mean(quality_stats['file_sizes']):.2f} MB\")\n",
        "print(f\"    Total: {np.sum(quality_stats['file_sizes']):.2f} MB\")\n",
        "\n",
        "# Check for uncommon aspect ratios\n",
        "aspect_ratios = np.array(quality_stats['widths']) / np.array(quality_stats['heights'])\n",
        "print(f\"\\n  Aspect Ratio (Image):\")\n",
        "print(f\"    Mean: {np.mean(aspect_ratios):.2f}\")\n",
        "print(f\"    Std: {np.std(aspect_ratios):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Visualize Image Quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize image quality metrics\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Resolution scatter plot\n",
        "axes[0].scatter(quality_stats['widths'], quality_stats['heights'], \n",
        "                alpha=0.5, s=50, color='steelblue')\n",
        "axes[0].set_xlabel('Image Width (pixels)', fontsize=11)\n",
        "axes[0].set_ylabel('Image Height (pixels)', fontsize=11)\n",
        "axes[0].set_title('Image Resolution Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# File size distribution\n",
        "axes[1].hist(quality_stats['file_sizes'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "axes[1].set_xlabel('File Size (MB)', fontsize=11)\n",
        "axes[1].set_ylabel('Frequency', fontsize=11)\n",
        "axes[1].set_title('Image File Size Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Sample Visualization with Bounding Boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_sample_with_bboxes(image_path, label_path, class_names=None):\n",
        "    \"\"\"Plot an image with its bounding boxes.\"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    img_array = np.array(img)\n",
        "    img_w, img_h = img.size\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "    ax.imshow(img_array)\n",
        "    \n",
        "    # Parse and draw bounding boxes\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = list(map(float, line.strip().split()))\n",
        "            if len(parts) >= 5:\n",
        "                class_id = int(parts[0])\n",
        "                x_center, y_center, bbox_w, bbox_h = parts[1:5]\n",
        "                \n",
        "                # Convert from normalized center coordinates to pixel coordinates\n",
        "                x_center *= img_w\n",
        "                y_center *= img_h\n",
        "                bbox_w *= img_w\n",
        "                bbox_h *= img_h\n",
        "                \n",
        "                # Convert to top-left corner coordinates\n",
        "                x_min = x_center - bbox_w / 2\n",
        "                y_min = y_center - bbox_h / 2\n",
        "                \n",
        "                # Draw rectangle\n",
        "                rect = Rectangle((x_min, y_min), bbox_w, bbox_h, \n",
        "                                linewidth=2, edgecolor='red', facecolor='none')\n",
        "                ax.add_patch(rect)\n",
        "                \n",
        "                # Add class label\n",
        "                label_text = f\"Class {class_id}\" if class_names is None else class_names.get(class_id, f\"Class {class_id}\")\n",
        "                ax.text(x_min, y_min - 5, label_text, fontsize=10, \n",
        "                       color='white', bbox=dict(facecolor='red', alpha=0.7))\n",
        "    \n",
        "    ax.set_title(f\"Sample: {Path(image_path).name}\", fontsize=12, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Plot sample images\n",
        "sample_images = list((IMAGES_DIR / 'train').glob('*.jpg'))[:5]  # First 5 images\n",
        "\n",
        "for img_path in sample_images:\n",
        "    label_path = LABELS_DIR / 'train' / (img_path.stem + '.txt')\n",
        "    if label_path.exists():\n",
        "        plot_sample_with_bboxes(img_path, label_path)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Data Augmentation Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from albumentations import (\n",
        "    Compose, HorizontalFlip, VerticalFlip, Rotate, GaussNoise,\n",
        "    ColorJitter, RandomBrightnessContrast, GaussBlur, Normalize\n",
        ")\n",
        "\n",
        "# Define augmentation pipeline\n",
        "augment_transform = Compose([\n",
        "    HorizontalFlip(p=0.5),\n",
        "    VerticalFlip(p=0.3),\n",
        "    Rotate(limit=15, p=0.5),\n",
        "    RandomBrightnessContrast(p=0.5),\n",
        "    GaussNoise(p=0.3),\n",
        "    GaussBlur(blur_limit=3, p=0.3),\n",
        "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.5),\n",
        "], bbox_params=None)  # Update with appropriate bbox_params for your use case\n",
        "\n",
        "print(\"Augmentation pipeline defined with:\")\n",
        "print(\"  - Horizontal Flip (50%)\")\n",
        "print(\"  - Vertical Flip (30%)\")\n",
        "print(\"  - Rotation (15°, 50%)\")\n",
        "print(\"  - Brightness/Contrast (50%)\")\n",
        "print(\"  - Gaussian Noise (30%)\")\n",
        "print(\"  - Gaussian Blur (30%)\")\n",
        "print(\"  - Color Jitter (50%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Visualize Augmentation Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a sample image for augmentation visualization\n",
        "sample_img_path = list((IMAGES_DIR / 'train').glob('*.jpg'))[0]\n",
        "sample_img = cv2.imread(str(sample_img_path))\n",
        "sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Create augmented versions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Original image\n",
        "axes[0].imshow(sample_img)\n",
        "axes[0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Augmented versions\n",
        "for i in range(1, 6):\n",
        "    augmented = augment_transform(image=sample_img)['image']\n",
        "    axes[i].imshow(augmented)\n",
        "    axes[i].set_title(f'Augmented Version {i}', fontsize=12, fontweight='bold')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive summary\n",
        "print(\"=\"*60)\n",
        "print(\"DATASET SUMMARY\".center(60))\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal images: {len(quality_stats['widths'])}\")\n",
        "print(f\"Total annotations: {total_annots}\")\n",
        "print(f\"Number of classes: {len(class_counts)}\")\n",
        "print(f\"Average annotations per image: {total_annots / len(quality_stats['widths']):.2f}\")\n",
        "print(f\"\\nTotal dataset size: {np.sum(quality_stats['file_sizes']):.2f} MB\")\n",
        "print(f\"\\nClass balance: {'Good' if max(class_counts.values()) / min(class_counts.values()) < 2 else 'Imbalanced'}\")\n",
        "print(f\"\\nRecommendations:\")\n",
        "print(f\"  - Consider class weighting: {class_counts}\")\n",
        "print(f\"  - Use data augmentation for underrepresented classes\")\n",
        "print(f\"  - Monitor small objects (< 1000 px²)\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
